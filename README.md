# Data science project template

[![Poetry](https://img.shields.io/endpoint?url=https://python-poetry.org/badge/v0.json)](https://python-poetry.org/)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v1.json)](https://github.com/charliermarsh/ruff)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![pages-build-deployment](https://github.com/JoseRZapata/data-science-project-template/actions/workflows/pages/pages-build-deployment/badge.svg?branch=gh-pages)](https://github.com/JoseRZapata/data-science-project-template/actions/workflows/pages/pages-build-deployment)
[![codecov](https://codecov.io/gh/JoseRZapata/data-science-project-template/graph/badge.svg?token=7LCPX574UF)](https://codecov.io/gh/JoseRZapata/data-science-project-template)
---

A modern template for data science projects with all the necessary tools for experiment, development, testing, and deployment. From notebooks to production.

Documentation: <https://joserzapata.github.io/data-science-project-template/>

Source Code: <https://github.com/JoseRZapata/data-science-project-template>

---

Table of Contents

- [Data science project template](#data-science-project-template)
  - [](#)
  - [📁 Creating a New Project](#-creating-a-new-project)
    - [👍 Recommendations](#-recommendations)
    - [🍪🥇 Via Cruft - **recommended**](#-via-cruft---recommended)
    - [🍪 Via Cookiecutter](#-via-cookiecutter)
  - [🔗  Linking an Existing Project](#--linking-an-existing-project)
  - [🗃️ Project structure](#️-project-structure)
  - [✨ Features and Tools](#-features-and-tools)
    - [🚀 Project Standardization and Automation](#-project-standardization-and-automation)
      - [🔨 Developer Workflow Automation](#-developer-workflow-automation)
      - [🌱 Conditionally Rendered Python Package or Project Boilerplate](#-conditionally-rendered-python-package-or-project-boilerplate)
    - [🔧 Maintainability](#-maintainability)
      - [🏷️  Type Checking and Data Validation](#️--type-checking-and-data-validation)
      - [✅ 🧪 Testing/Coverage](#--testingcoverage)
      - [🚨 Linting](#-linting)
        - [🔍 Code quality](#-code-quality)
        - [🎨 Code formatting](#-code-formatting)
      - [👷 CI/CD](#-cicd)
  - [🔒 Security](#-security)
    - [🔏 Static Application Security Testing (SAST)](#-static-application-security-testing-sast)
  - [⌨️ Accessibility](#️-accessibility)
    - [🔨 Automation tool (Makefile)](#-automation-tool-makefile)
    - [📝 Project Documentation](#-project-documentation)
    - [🗃️ Templates](#️-templates)
  - [References](#references)

## 📁 Creating a New Project

### 👍 Recommendations

It is highly recommended to use a python version manager like [Pyenv] and this project is set to use [Poetry] to manage the dependencies and the environment.

**Note:** [Poetry] should always be installed in a dedicated virtual environment to isolate it from the rest of your system. [why?](https://python-poetry.org/docs/#installation)

🌟 Check how to setup your environment: <https://joserzapata.github.io/data-science-project-template/local_setup/>

### 🍪🥇 Via [Cruft] - **recommended**

```bash title="install cruft"
pip install --user cruft # Install `cruft` on your path for easy access
```

```shell title="create project"
cruft create https://github.com/JoseRZapata/data-science-project-template
```

### 🍪 Via [Cookiecutter]

```shell title="install cookiecutter"
pip install --user cookiecutter # Install `cookiecutter` on your path for easy access
```

```shell title="create project"
cookiecutter gh:JoseRZapata/data-science-project-template
```

Note: **_Cookiecutter_** uses `gh:` as short-hand for `https://github.com/`

## 🔗  Linking an Existing Project

If the project was originally installed via [Cookiecutter], you must first use [Cruft] to link the project with the original template:

```shell
cruft link https://github.com/JoseRZapata/data-science-project-template
```

Then/else:

```shell
cruft update
```

## 🗃️ Project structure

Folder structure for data science projects  [why?](https://towardsdatascience.com/the-importance-of-layered-thinking-in-data-engineering-a09f685edc71)

[Data structure]

```bash
.
├── codecov.yml                         # configuration for codecov
├── .code_quality
│   ├── bandit.yaml                     # bandit configuration
│   ├── mypy.ini                        # mypy configuration
│   └── ruff.toml                       # ruff configuration
├── data
│   ├── 01_raw                          # raw immutable data
│   ├── 02_intermediate                 # typed data
│   ├── 03_primary                      # domain model data
│   ├── 04_feature                      # model features
│   ├── 05_model_input                  # often called 'master tables'
│   ├── 06_models                       # serialized models
│   ├── 07_model_output                 # data generated by model runs
│   ├── 08_reporting                    # reports, results, etc
│   └── README.md                       # description of the data structure
├── docs                                # documentation for your project
├── .editorconfig                       # editor configuration
├── .github                             # github configuration
│   ├── actions
│   │   └── python-poetry-env
│   │       └── action.yml              # github action to setup python environment
│   ├── dependabot.md                   # github action to update dependencies
│   ├── pull_request_template.md        # template for pull requests
│   └── workflows
│       ├── docs.yml                    # github action to build documentation (mkdocs)
│       ├── pre-commit_autoupdate.yml   # github action update pre-commit hooks
│       └── test.yml
├── .gitignore                          # files to ignore in git
├── Makefile                            # useful commands to setup environment,
├── models                              # store final models
├── notebooks
│   ├── 1-data                          # notebooks for data extraction and cleaning
│   ├── 2-exploration                   # notebooks for data exploration
│   ├── 3-analysis                      # notebooks for data analysis
│   ├── 4-feat_eng                      # notebooks for feature engineering
│   ├── 5-models                        # notebooks for model training
│   ├── 6-evaluation                    # notebooks for model evaluation
│   ├── 7-deploy                        # notebooks for model deployment
│   ├── notebook_template.ipynb         # template for notebooks
│   └── README.md                       # information about the notebooks
├── .pre-commit-config.yaml             # configuration for pre-commit hooks
├── pyproject.toml                      # dependencies for poetry
├── README.md                           # description of your project
├── src                                 # source code for use in this project
├── tests                               # test code for your project
└── .vscode                             # vscode configuration
    ├── extensions.json                 # list of recommended extensions
    └── settings.json                   # vscode settings
```

## ✨ Features and Tools

### 🚀 Project Standardization and Automation

#### 🔨 Developer Workflow Automation

- Python packaging, dependency management and environment management
  with [Poetry] - [`why?`](https://mathdatasimplified.com/poetry-a-better-way-to-manage-python-dependencies/)
- Project workflow orchestration
  with [Make] as an [interface shim](https://en.wikipedia.org/wiki/Shim_(computing))
  - Self-documenting [Makefile](https://github.com/JoseRZapata/data-science-project-template/blob/main/{{cookiecutter.repo_name}}/Makefile); just type
      `make` on the command line to display auto-generated documentation on available
      targets:
- Automated Cookiecutter template synchronization with [Cruft] - [`why?`](https://careers.wolt.com/en/blog/tech/project-template-for-modern-python-packages)
- Code quality tooling automation and management with [pre-commit]
- Continuous integration and deployment with [GitHub Actions]
- Project configuration files  with [Hydra] - [`why?`](https://mathdatasimplified.com/stop-hard-coding-in-a-data-science-project-use-configuration-files-instead/)

#### 🌱 Conditionally Rendered Python Package or Project Boilerplate

- _Optional:_ [Jupyter] support

### 🔧 Maintainability

#### 🏷️  Type Checking and Data Validation

- Static type-checking with [Mypy]

#### ✅ 🧪 Testing/Coverage

- Testing with [Pytest]
- Code coverage with [Coverage.py]
- Coverage reporting with [Codecov]

#### 🚨 Linting

##### 🔍 Code quality

- [Ruff] An extremely fast (10x-100x faster) Python linter and code formatter, written in Rust.
  - Replacement for [Pylint], [Flake8] (including major plugins) and more linters under a single, common interface
- [ShellCheck](https://github.com/koalaman/shellcheck)
- Unsanitary commits:
  - Secrets
    with [`detect-secrets`](https://github.com/Yelp/detect-secrets)
  - Large files
    with [`check-added-large-files`](https://github.com/pre-commit/pre-commit-hooks#check-added-large-files)
  - Invalid Python files
    with [`check-ast`](https://github.com/pre-commit/pre-commit-hooks#check-ast)

##### 🎨 Code formatting

- [Ruff] An extremely fast (10x-100x faster) Python linter and code formatter, written in Rust.
  - Replacement for [Black], [isort], [pyupgrade] and more formatters under a single, common interface

- General file formatting:
  - [`end-of-file-fixer`](https://github.com/pre-commit/pre-commit-hooks#end-of-file-fixer)
  - [`pretty-format-json`](https://github.com/pre-commit/pre-commit-hooks#pretty-format-json)
  - (trim) [`trailing-whitespace`](https://github.com/pre-commit/pre-commit-hooks#trailing-whitespace)
  - [`check-yaml`](https://github.com/pre-commit/pre-commit-hooks#check-yaml)

#### 👷 CI/CD

- **Dependency updates**
  with [Dependabot]
  - Automated [Dependabot] PR merging with the [Dependabot Auto Merge GitHub Action](https://github.com/ahmadnassri/action-dependabot-auto-merge)
    - Replacement for [pip-audit](https://github.com/pypa/pip-audit) , _In your local environment,
       If you want to check for vulnerabilities in your dependencies you can install this tool_.

- **Pre-commit automatic updates** with [GitHub Actions] workflow `.github/workflows/pre-commit_autoupdate.yml`

## 🔒 Security

### 🔏 Static Application Security Testing (SAST)

- Code vulnerabilities with [Bandit]

## ⌨️ Accessibility

### 🔨 Automation tool (Makefile)

Makefile to automate the setup of your environment, the installation of dependencies, the execution of tests, etc.
in terminal type `make` to see the available commands

```bash
Target                         Description
-----------------------        ----------------------------------------------------
init_env                       Install dependencies with poetry and init git
install_all_libs               Install libraries for data science and ML
install_data_libs              Install pandas and numpy
install_ml_libs                Install scikit-learn
install_viz_libs               Install matplotlib seaborn plotly dev group
tests                          Run tests with coverage
```

### 📝 Project Documentation

- Documentation building
  with [MkDocs] - [Tutorial](https://realpython.com/python-project-documentation-with-mkdocs/)
  - Powered by [mkdocs-material](https://github.com/squidfunk/mkdocs-material)
  - Rich automatic documentation from type annotations and docstrings (NumPy, Google, etc.)
    with [mkdocstrings]

### 🗃️ Templates

- [Pull Request template]
- [Notebook template]

---

## References

- <https://drivendata.github.io/cookiecutter-data-science/>
- <https://github.com/crmne/cookiecutter-modern-datascience>
- <https://github.com/fpgmaas/cookiecutter-poetry>
- <https://github.com/khuyentran1401/data-science-template>
- <https://github.com/woltapp/wolt-python-package-cookiecutter>
- <https://khuyentran1401.github.io/reproducible-data-science/structure_project/introduction.html>
- <https://github.com/TeoZosa/cookiecutter-cruft-poetry-tox-pre-commit-ci-cd>
- <https://github.com/cjolowicz/cookiecutter-hypermodern-python>
- <https://github.com/kedro-org/kedro-starters>

---

[Bandit]: https://github.com/PyCQA/bandit
[Black]: https://github.com/psf/black
[Codecov]: https://codecov.io/
[Cookiecutter]:https://cookiecutter.readthedocs.io/stable/
[Coverage.py]: https://coverage.readthedocs.io/
[Cruft]: https://cruft.github.io/cruft/
[Data structure]: https://github.com/JoseRZapata/data-science-project-template/blob/main/{{cookiecutter.repo_name}}/data/README.md
[deepcheck]:https://deepcheck.io/
[Dependabot]: https://github.com/dependabot/dependabot-core
[DVC]:https://dvc.org/
[Flake8]:https://github.com/PyCQA/flake8
[GitHub Actions]: https://github.com/features/actions
[github labeler]: https://github.com/marketplace/actions/github-labeler
[hydra]: https://hydra.cc/
[isort]: https://github.com/PyCQA/isort
[Jupyter]: https://jupyter.org/
[Make]: https://www.gnu.org/software/make/manual/make.html
[mkdocs]: https://www.mkdocs.org/
[mkdocstrings]: https://mkdocstrings.github.io/
[MlFlow]:https://www.mlflow.org/
[Mypy]: http://mypy-lang.org/
[Notebook template]: https://github.com/JoseRZapata/data-science-project-template/blob/main/{{cookiecutter.repo_name}}/notebooks/notebook_template.ipynb
[NumPy]:https://numpy.org/
[OmegaConf]: https://omegaconf.readthedocs.io/en/latest/
[Pandas]:https://pandas.pydata.org/
[pandera]:(https://pandera.readthedocs.io/en/stable/)
[Poetry]: https://python-poetry.org/
[pre-commit]: https://pre-commit.com/
[Pull Request template]: https://github.com/JoseRZapata/data-science-project-template/blob/main/{{cookiecutter.repo_name}}/.github/pull_request_template.md
[Pyenv]: https://github.com/pyenv/pyenv
[Pylint]:https://github.com/PyCQA/pylint
[pypi]: https://pypi.org/
[Pytest]: https://docs.pytest.org/en/latest/
[pyupgrade]: https://github.com/asottile/pyupgrade
[Ruff]: https://docs.astral.sh/ruff/
[scikit-learn]:https://scikit-learn.org/
