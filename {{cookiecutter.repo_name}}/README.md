# {{cookiecutter.project_name}}

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v2.json)](https://github.com/charliermarsh/ruff)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![security: bandit](https://img.shields.io/badge/security-bandit-yellow.svg)](https://github.com/PyCQA/bandit)
[![Checked with mypy](https://www.mypy-lang.org/static/mypy_badge.svg)](https://mypy-lang.org/)

This is a data science project template created with [Cookiecutter] to help you start your next data science or machine learning project quickly and efficiently. It includes a well-organized folder structure, essential tools for code quality, testing, and documentation, and follows best practices in the industry.

Using the data science project template <https://github.com/JoseRZapata/data-science-project-template>

## âœ¨ Features and Tools

Information about all the features and tools used in this project: <https://joserzapata.github.io/data-science-project-template/#features-and-tools>

Features                                     | Package  | Why?
 ---                                         | ---      | ---
Dependencies and env                         | [UV] | [article](https://astral.sh/blog/uv)
Lint - Format, sort imports  (Code Quality)  | [Ruff] | [article](https://www.sicara.fr/blog-technique/boost-code-quality-ruff-linter)
Static type checking                         | [Mypy] | [article](https://python.plainenglish.io/does-python-need-types-79753b88f521)
code security                                | [bandit] | [article](https://blog.bytehackr.in/secure-your-python-code-with-bandit)
Code quality & security each commit          | [pre-commit] | [article](https://dev.to/techishdeep/maximize-your-python-efficiency-with-pre-commit-a-complete-but-concise-guide-39a5)
Test code                                    | [Pytest] | [article](https://realpython.com/pytest-python-testing/)
Test coverage                                | [coverage.py] [codecov] | [article](https://martinxpn.medium.com/test-coverage-in-python-with-pytest-86-100-days-of-python-a3205c77296)
Project Template                             | [Cruft] or [Cookiecutter] | [article](https://medium.com/@bctello8/standardizing-dbt-projects-at-scale-with-cookiecutter-and-cruft-20acc4dc3f74)
Folder structure for data science projects   | [Data structure] | [article](https://towardsdatascience.com/the-importance-of-layered-thinking-in-data-engineering-a09f685edc71)
Template for pull requests                   | [Pull Request template] | [article](https://www.awesomecodereviews.com/pull-request-template/)
Template for notebooks                       | [Notebook template] |

## Set up the environment

1. Initialize git in local:

    ```bash
    make init_git
    ```

1. Set up the environment:

    ```bash
    make install_env
    ```

1. Activate virtual environment:

    ```bash
    source .venv/bin/activate
    ```

1. Install libraries for data science and machine learning:

    ```bash
    make install_data_libs
    ```

## Install dependencies

After init the environment to install a new package, run:

```bash
uv add <package-name>
```

Example to install [plotly](https://plotly.com/python/) in dev group:

```bash
uv add --group dev plotly
```

## ğŸ—ƒï¸ Project structure

- [Data structure]
- [Pipelines based on Feature/Training/Inference Pipelines](https://www.hopsworks.ai/post/mlops-to-ml-systems-with-fti-pipelines)

```bash
.
â”œâ”€â”€ codecov.yml                         # configuration for codecov
â”œâ”€â”€ .code_quality
â”‚Â Â  â”œâ”€â”€ mypy.ini                        # mypy configuration
â”‚Â Â  â””â”€â”€ ruff.toml                       # ruff configuration
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ 01_raw                          # raw immutable data
â”‚Â Â  â”œâ”€â”€ 02_intermediate                 # typed data
â”‚Â Â  â”œâ”€â”€ 03_primary                      # domain model data
â”‚Â Â  â”œâ”€â”€ 04_feature                      # model features
â”‚Â Â  â”œâ”€â”€ 05_model_input                  # often called 'master tables'
â”‚Â Â  â”œâ”€â”€ 06_models                       # serialized models
â”‚Â Â  â”œâ”€â”€ 07_model_output                 # data generated by model runs
â”‚Â Â  â”œâ”€â”€ 08_reporting                    # reports, results, etc
â”‚Â Â  â””â”€â”€ README.md                       # description of the data structure
â”œâ”€â”€ docs                                # documentation for your project
â”œâ”€â”€ .editorconfig                       # editor configuration
â”œâ”€â”€ .github                             # github configuration
â”‚Â Â  â”œâ”€â”€ dependabot.md                   # github action to update dependencies
â”‚Â Â  â”œâ”€â”€ pull_request_template.md        # template for pull requests
â”‚Â Â  â””â”€â”€ workflows                       # github actions workflows
â”‚Â Â      â”œâ”€â”€ ci.yml                      # run continuous integration (tests, pre-commit, etc.)
â”‚Â Â      â”œâ”€â”€ dependency_review.yml       # review dependencies
â”‚Â Â      â”œâ”€â”€ docs.yml                    # build documentation (mkdocs)
â”‚Â Â      â””â”€â”€ pre-commit_autoupdate.yml   # update pre-commit hooks
â”œâ”€â”€ .gitignore                          # files to ignore in git
â”œâ”€â”€ Makefile                            # useful commands to setup environment, run tests, etc.
â”œâ”€â”€ models                              # store final models
â”œâ”€â”€ notebooks
â”‚Â Â  â”œâ”€â”€ 1-data                          # data extraction and cleaning
â”‚Â Â  â”œâ”€â”€ 2-exploration                   # exploratory data analysis (EDA)
â”‚Â Â  â”œâ”€â”€ 3-analysis                      # Statistical analysis, hypothesis testing.
â”‚Â Â  â”œâ”€â”€ 4-feat_eng                      # feature engineering (creation, selection, and transformation.)
â”‚Â Â  â”œâ”€â”€ 5-models                        # model training, evaluation, and hyperparameter tuning.
â”‚Â Â  â”œâ”€â”€ 6-interpretation                # model interpretation
â”‚Â Â  â”œâ”€â”€ 7-deploy                        # model packaging, deployment strategies.
â”‚Â Â  â”œâ”€â”€ 8-reports                       # story telling, summaries and analysis conclusions.
â”‚Â Â  â”œâ”€â”€ notebook_template.ipynb         # template for notebooks
â”‚Â Â  â””â”€â”€ README.md                       # information about the notebooks
â”œâ”€â”€ .pre-commit-config.yaml             # configuration for pre-commit hooks
â”œâ”€â”€ pyproject.toml                      # dependencies for the python project
â”œâ”€â”€ README.md                           # description of your project
â”œâ”€â”€ src                                 # source code for use in this project
â”‚   â”œâ”€â”€ README.md                       # description of src structure
â”‚   â”œâ”€â”€ tmp_mock.py                     # example python file
â”‚   â”œâ”€â”€ data                            # data extraction, validation, processing, transformation
â”‚   â”œâ”€â”€ model                           # model training, evaluation, validation, export
â”‚   â”œâ”€â”€ inference                       # model prediction, serving, monitoring
â”‚   â””â”€â”€ pipelines                       # orchestration of pipelines
â”‚       â”œâ”€â”€ feature_pipeline            # transforms raw data into features and labels
â”‚       â”œâ”€â”€ training_pipeline           # transforms features and labels into a model
â”‚       â””â”€â”€ inference_pipeline          # takes features and a trained model for predictions
â”œâ”€â”€ tests                               # test code for your project
â”‚   â”œâ”€â”€ test_mock.py                    # example test file
â”‚   â”œâ”€â”€ data                            # tests for data module
â”‚   â”œâ”€â”€ model                           # tests for model module
â”‚   â”œâ”€â”€ inference                       # tests for inference module
â”‚   â””â”€â”€ pipelines                       # tests for pipelines module
â””â”€â”€ .vscode                             # vscode configuration
    â”œâ”€â”€ extensions.json                 # list of recommended extensions
    â”œâ”€â”€ launch.json                     # vscode launch configuration
    â””â”€â”€ settings.json                   # vscode settings
```

## Credits

This project was generated from [@JoseRZapata]'s [data science project template] template.

---
[@JoseRZapata]: https://github.com/JoseRZapata

[bandit]: https://github.com/PyCQA/bandit
[codecov]: https://codecov.io/
[Cookiecutter]:https://cookiecutter.readthedocs.io/en/stable/
[coverage.py]: https://coverage.readthedocs.io/
[Cruft]: https://cruft.github.io/cruft/
[data science project template]: https://github.com/JoseRZapata/data-science-project-template
[Data structure]: https://github.com/JoseRZapata/data-science-project-template/blob/main/{{cookiecutter.repo_name}}/data/README.md
[Mypy]: http://mypy-lang.org/
[Notebook template]: {{cookiecutter.repo_name}}/notebooks/notebook_template.ipynb
[pre-commit]: https://pre-commit.com/
[Pull Request template]: {{cookiecutter.repo_name}}/.github/pull_request_template.md
[Pytest]: https://docs.pytest.org/en/latest/
[Ruff]: https://docs.astral.sh/ruff/
[UV]: https://docs.astral.sh/uv/
